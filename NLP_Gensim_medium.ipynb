{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, FastText\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['i', 'like', 'apple', 'pie', 'for', 'dessert'],\n",
    "            ['i', 'dont', 'drive', 'fast', 'cars'],\n",
    "            ['data', 'science', 'is', 'fun'],\n",
    "            ['chocolate', 'is', 'my', 'favorite'],\n",
    "            ['my', 'favorite', 'movie', 'is', 'predator']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train word2vec model\n",
    "w2v = Word2Vec(sentences, min_count=1, size = 5)\n",
    "print(w2v)\n",
    "\n",
    "#train fastText model\n",
    "ft = FastText(sentences, min_count=1, size = 5)\n",
    "print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize vocabulary\n",
    "words1 = list(w2v.wv.vocab)\n",
    "print(words1)\n",
    "w2v.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access vector for one word\n",
    "print(w2v['chocolate'])\n",
    "print(ft['chocolate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = w2v[w2v.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "# create a scatter plot of the projection\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(w2v.wv.vocab)\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ft[ft.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(ft.wv.vocab)\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_txt = []\n",
    "for w in range(len(df.text)):\n",
    "    desc = df['text'][w].lower()\n",
    "    \n",
    "    #remove punctuation\n",
    "    desc = re.sub('[^a-zA-Z]', ' ', desc)\n",
    "    \n",
    "    #remove tags\n",
    "    desc=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",desc)\n",
    "    \n",
    "    #remove digits and special chars\n",
    "    desc=re.sub(\"(\\\\d|\\\\W)+\",\" \",desc)\n",
    "    clean_txt.append(desc)\n",
    "\n",
    "df['clean'] = clean_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for col in df.clean:\n",
    "    word_list = col.split(\" \")\n",
    "    corpus.append(word_list)\n",
    "corpus[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(corpus, min_count=1, size = 56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model[model.wv.vocab]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.vocab)\n",
    "\n",
    "for i, word in enumerate(words):\n",
    "    pyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pass the embeddings to PCA\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "#create df from the pca results\n",
    "pca_df = pd.DataFrame(result, columns = ['x','y'])\n",
    "\n",
    "#add the words for the hover effect\n",
    "pca_df['word'] = words\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000000\n",
    "words = list(model.wv.vocab)\n",
    "fig = go.Figure(data=go.Scattergl(\n",
    "    x = pca_df['x'],\n",
    "    y = pca_df['y'],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        color=np.random.randn(N),\n",
    "        colorscale='Viridis',\n",
    "        line_width=1\n",
    "    ),\n",
    "    text=pca_df['word'],\n",
    "    textposition=\"bottom center\"\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('eric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar_cosmul(positive = ['phone', 'number'], negative = ['call'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match(\"phone number prison cell\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save embeddings\n",
    "file = 'email_embd.txt'\n",
    "model.wv.save_word2vec_format(file, binary = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# embeddings_index = {}\n",
    "\n",
    "# f = open(os.path.join('', 'email_embd.txt'), encoding = 'utf-8')\n",
    "# for line in f:\n",
    "#     values = line.split()\n",
    "#     word = values[0]\n",
    "#     coefs = np.asarray(values[1:])\n",
    "#     embeddings_index[word] = coefs\n",
    "# f.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/reiinakano/basic-nlp-bag-of-words-tf-idf-word2vec-lstm\n",
    "import nltk\n",
    "\n",
    "class MyTokenizer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_X = []\n",
    "        for document in X:\n",
    "            tokenized_doc = []\n",
    "            for sent in nltk.sent_tokenize(document):\n",
    "                tokenized_doc += nltk.word_tokenize(sent)\n",
    "            transformed_X.append(np.array(tokenized_doc))\n",
    "        return np.array(transformed_X)\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = len(word2vec.wv.syn0[0])\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = MyTokenizer().fit_transform(X)\n",
    "        \n",
    "        return np.array([\n",
    "            np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(X):\n",
    "    #X = MyTokenizer().fit_transform(X)\n",
    "\n",
    "    return np.array([\n",
    "        np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "                or [np.zeros(self.dim)], axis=0)\n",
    "        for words in X\n",
    "    ])\n",
    "\n",
    "t = transform(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedding_vectorizer = MeanEmbeddingVectorizer(model)\n",
    "mean_embedded = mean_embedding_vectorizer.fit_transform(df['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_embedded[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['array'] = list(mean_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
